<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithm Reflections</title>
    <style>
        body {
            font-family: 'Product Sans', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #e6f7ff;
            color: #333;
        }
        h1 {
            text-align: center;
            color: white;
            background-color: #004080;
            padding: 20px;
        }
        h2 {
            color: #004080;
        }
        section {
            margin-bottom: 20px;
            padding: 15px;
            background: #ffffff;
            border-radius: 8px;
        }
        p {
            margin: 0 0 10px;
        }
        .button-container {
            text-align: center;
            margin-top: 20px;
        }
        .button-container a {
            display: inline-block;
            padding: 10px 20px;
            text-decoration: none;
            background-color: #004080;
            color: white;
            border-radius: 5px;
            font-weight: bold;
            transition: background-color 0.3s ease; 
            margin-bottom: 10px;
        }
        .button-container a:hover {
            background-color: #0059b3;
        }
    </style>
</head>
<body>

    <h1>Reflections</h1>

    <section>
        <h2>What are the kinds of problems we see in nature?</h2>
        <p>Nature is full of challenges that require innovative solutions. Some problems occur in repetitive patterns, like the cycles of seasons, which are best solved iteratively. Others, like the structure of tree branches or snowflakes, break down into smaller self-similar patterns, which can be solved using recursion. Some problems, like an ant finding its way through a maze, are more complex and require a trial-and-error approach, resembling backtracking. Each of these approaches—iteration, recursion, and backtracking—mimics nature’s way of finding effective solutions.</p>
    </section>

    <section>
        <h2>What is space and time efficiency? Why are they important?</h2>
        <p>Space efficiency is about how much memory a program uses, while time efficiency measures how quickly it runs. Both are crucial because resources like memory and time are limited. Imagine an app that crashes your phone because it uses too much memory or a program that takes hours to process simple tasks—it wouldn’t be practical or effective. Efficiency ensures that software runs smoothly, even as the amount of data grows or devices become smaller with less capacity.</p>
    </section>

    <section>
        <h2>Takeaway from different design principles from Chapter 2</h2>
        <p>Chapter 2 taught me the importance of breaking down problems and solving them systematically. For example, modular design emphasizes dividing problems into smaller parts, which makes them easier to tackle and debug. The divide-and-conquer approach showed me that breaking problems into halves, solving each, and combining results—like in merge sort—can save time. Optimization stood out as well, especially with techniques like dynamic programming, where small improvements can significantly boost efficiency.</p>
    </section>

    <section>
        <h2>The hierarchical data and how different tree data structures solve problems</h2>
        <p>Hierarchical data is everywhere—file systems, organization charts, or game levels. Trees are perfect for managing this kind of data. Binary search trees are great for quickly searching and sorting. AVL trees and red-black trees ensure balance, so operations are consistent even with uneven data. Heaps are a lifesaver when managing priorities, like scheduling tasks. These structures aren’t just abstract concepts—they help solve real problems efficiently.</p>
    </section>

    <section>
        <h2>The need for array query algorithms and their implications</h2>
        <p>Imagine trying to get answers about sections of a giant dataset repeatedly—doing it from scratch every time would be painfully slow. That’s where array query algorithms come in. For example, segment trees help with range-based queries like summing numbers in a range or finding a maximum. Fenwick trees make updates fast while keeping everything organized. These tools make handling large amounts of data more manageable and efficient, especially in applications like databases and coding competitions.</p>
    </section>

    <section>
        <h2>Differentiate between trees and graphs and their traversals</h2>
        <p>Trees and graphs both deal with nodes and connections, but they’re used for different purposes. Trees are like organized family trees—everything follows a hierarchy, and there’s only one way to connect any two nodes. Graphs are messier, like a web, with connections going anywhere. Traversals like DFS and BFS help explore these structures, whether it’s for hierarchical trees or networks like maps and social media connections.</p>
    </section>

    <section>
        <h2>Deliberate on sorting and searching algorithms</h2>
        <p>Sorting and searching are the backbone of efficient data handling. Sorting makes things easier to find or use later, like alphabetizing a list of contacts. Algorithms like quicksort and merge sort ensure this is done in a smart way. Searching, on the other hand, helps pinpoint what you need—binary search is super fast but needs sorted data, while linear search works everywhere but can be slow. Together, they keep data accessible and usable.</p>
    </section>

    <section>
        <h2>The importance of graph algorithms</h2>
        <p>Graph algorithms are essential for solving real-world problems, like finding the shortest route on Google Maps. They optimize connections in transportation, communication, or social networks. Algorithms like Dijkstra’s for shortest paths or Kruskal’s for building efficient networks are practical tools that directly impact areas like logistics and network design. They’re fascinating because they mirror real challenges we face daily.</p>
    </section>

    <section>
        <h2>Different studied algorithm design techniques</h2>
        <p>The different design techniques we learned—like greedy algorithms, dynamic programming, and divide-and-conquer—all stood out for how systematic they are. Greedy algorithms are like quick decisions that work for problems like building an efficient file compression. Dynamic programming is about carefully building on smaller solutions, like solving puzzles one piece at a time. Divide-and-conquer, meanwhile, felt like breaking a big task into manageable parts—something we do in everyday life, like organizing a big project. These approaches make solving complex problems a lot simpler.</p>
    </section>

</body>
</html>
